{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the Average Height of US Presidents?\n",
    "\n",
    "Aggregates available in NumPy can be extremely useful for summarizing a set of values.\n",
    "As a simple example, let's consider the heights of all US presidents.\n",
    "\n",
    "This data is available in the file *president_heights.csv*, which is a simple comma-separated list of labels and values.\n",
    "\n",
    "Find the mean height, the standard deviation of height, and the president who is the smallest and tallest.\n",
    "\n",
    "You can use `pandas` to read in the file if you want, then cast the column to a `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.73809523809524 is the mean height of US presidents\n",
      "6.931843442745892 is the standard deviation of the heights of US presidents\n",
      "At 163 cm tall, James Madison was the shortest president\n",
      "At 193 cm tall, Lyndon B. Johnson and Abraham Lincoln were the tallest presidents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['James Madison', 163],\n",
       "       ['Martin Van Buren', 168],\n",
       "       ['Benjamin Harrison', 168],\n",
       "       ['John Adams', 170],\n",
       "       ['William McKinley', 170],\n",
       "       ['John Quincy Adams', 171],\n",
       "       ['William Henry Harrison', 173],\n",
       "       ['James K. Polk', 173],\n",
       "       ['Zachary Taylor', 173],\n",
       "       ['Ulysses S. Grant', 173],\n",
       "       ['Rutherford B. Hayes', 174],\n",
       "       ['Millard Fillmore', 175],\n",
       "       ['Harry S. Truman', 175],\n",
       "       ['Jimmy Carter', 177],\n",
       "       ['Andrew Johnson', 178],\n",
       "       ['Franklin Pierce', 178],\n",
       "       ['Theodore Roosevelt', 178],\n",
       "       ['Calvin Coolidge', 178],\n",
       "       ['Dwight D. Eisenhower', 179],\n",
       "       ['Woodrow Wilson', 180],\n",
       "       ['George W. Bush', 182],\n",
       "       ['Herbert Hoover', 182],\n",
       "       ['Richard Nixon', 182],\n",
       "       ['William Howard Taft', 182],\n",
       "       ['Warren G. Harding', 183],\n",
       "       ['Chester A. Arthur', 183],\n",
       "       ['Gerald Ford', 183],\n",
       "       ['James Buchanan', 183],\n",
       "       ['John Tyler', 183],\n",
       "       ['James Monroe', 183],\n",
       "       ['James A. Garfield', 183],\n",
       "       ['John F. Kennedy', 183],\n",
       "       ['Ronald Reagan', 185],\n",
       "       ['Barack Obama', 185],\n",
       "       ['Andrew Jackson', 185],\n",
       "       ['Franklin D. Roosevelt', 188],\n",
       "       ['George H. W. Bush', 188],\n",
       "       ['Bill Clinton', 188],\n",
       "       ['Thomas Jefferson', 189],\n",
       "       ['George Washington', 189],\n",
       "       ['Abraham Lincoln', 193],\n",
       "       ['Lyndon B. Johnson', 193]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('C:/Users/farha/Documents/m1-6-numpy/data/president_heights.csv')\n",
    "\n",
    "array = df['height(cm)'].to_numpy()\n",
    "\n",
    "print(str(array.mean()) + \" is the mean height of US presidents\")\n",
    "print(str(np.std(array)) + \" is the standard deviation of the heights of US presidents\")\n",
    "\n",
    "df2 = df.drop('order', 1)\n",
    "array2 = df2.to_numpy()\n",
    "array3 = array2[array2[: , 1].argsort()]\n",
    "print(\"At \" + str(array3[0][1]) + \" cm tall, \" + str(array3[0][0]) + \" was the shortest president\")\n",
    "print(\"At \" + str(array3[-1][-1]) + \" cm tall, \" + str(array3[-1][0]) + \n",
    "      \" and \" + str(array3[-2][0]) + \" were the tallest presidents\")\n",
    "array3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Recall the polynomial formula\n",
    "\n",
    "$$\n",
    "p(x) = a_0 + a_1 x + a_2 x^2 + \\cdots a_N x^N = \\sum_{n=0}^N a_n x^n \\tag{1}\n",
    "$$\n",
    "\n",
    "In the **math functions workshop**, you wrote a simple function `p(x, coeff)` to evaluate it without thinking about efficiency.\n",
    "\n",
    "Now write a new function that does the same job, but uses NumPy arrays and array operations for its computations, rather than any form of Python loop.\n",
    "\n",
    "(This is already implemented in `np.poly1d`, but use that only to test your function)\n",
    "\n",
    "- Hint: Use `np.cumprod()`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def p(x, coeff):\n",
    "    '''\n",
    "    - use np.ones_like to create array as long as the length of coeff\n",
    "    - np.cumprod() to do x ** n\n",
    "    - coeff * y would be elementwise product whereas coeff @ y does the matrix product\n",
    "    '''\n",
    "    y = np.ones_like(coeff) \n",
    "    y[1:] = x #since the first number is to the power 0\n",
    "    z = np.cumprod(y) \n",
    "    return coeff @ y \n",
    "\n",
    "p(4, [5, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Softmax\n",
    "\n",
    "Read in `data/iris.csv` and compute the [softmax]() of the sepal length. The formula for the softmax function $\\sigma(x)$ for a vector $x = \\{x_0, x_1, ..., x_{n-1}\\}$ is\n",
    "    .$$\\sigma(x)_j = \\frac{e^{x_j}}{\\sum_k e^{x_k}}$$\n",
    "\n",
    "\n",
    "Your result should be equal to the output of `scipy.special.softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00221959, 0.00181724, 0.00148783, 0.00134625, 0.00200836,\n",
       "       0.00299613, 0.00134625, 0.00200836, 0.00110221, 0.00181724,\n",
       "       0.00299613, 0.00164431, 0.00164431, 0.00099732, 0.0044697 ,\n",
       "       0.00404435, 0.00299613, 0.00221959, 0.00404435, 0.00221959,\n",
       "       0.00299613, 0.00221959, 0.00134625, 0.00221959, 0.00164431,\n",
       "       0.00200836, 0.00200836, 0.00245302, 0.00245302, 0.00148783,\n",
       "       0.00164431, 0.00299613, 0.00245302, 0.00331123, 0.00181724,\n",
       "       0.00200836, 0.00331123, 0.00181724, 0.00110221, 0.00221959,\n",
       "       0.00200836, 0.00121813, 0.00110221, 0.00200836, 0.00221959,\n",
       "       0.00164431, 0.00221959, 0.00134625, 0.00271101, 0.00200836,\n",
       "       0.01483991, 0.00814432, 0.01342771, 0.00331123, 0.00900086,\n",
       "       0.00404435, 0.00736928, 0.00181724, 0.00994749, 0.00245302,\n",
       "       0.00200836, 0.00493978, 0.0054593 , 0.00603346, 0.00365948,\n",
       "       0.01099368, 0.00365948, 0.0044697 , 0.006668  , 0.00365948,\n",
       "       0.00493978, 0.00603346, 0.00736928, 0.00603346, 0.00814432,\n",
       "       0.00994749, 0.01214989, 0.01099368, 0.0054593 , 0.00404435,\n",
       "       0.00331123, 0.00331123, 0.0044697 , 0.0054593 , 0.00299613,\n",
       "       0.0054593 , 0.01099368, 0.00736928, 0.00365948, 0.00331123,\n",
       "       0.00331123, 0.00603346, 0.0044697 , 0.00200836, 0.00365948,\n",
       "       0.00404435, 0.00404435, 0.006668  , 0.00221959, 0.00404435,\n",
       "       0.00736928, 0.0044697 , 0.01640064, 0.00736928, 0.00900086,\n",
       "       0.02704008, 0.00181724, 0.02003179, 0.01099368, 0.01812551,\n",
       "       0.00900086, 0.00814432, 0.01214989, 0.00404435, 0.0044697 ,\n",
       "       0.00814432, 0.00900086, 0.02988391, 0.02988391, 0.0054593 ,\n",
       "       0.01342771, 0.00365948, 0.02988391, 0.00736928, 0.01099368,\n",
       "       0.01812551, 0.006668  , 0.00603346, 0.00814432, 0.01812551,\n",
       "       0.02213855, 0.0365003 , 0.00814432, 0.00736928, 0.00603346,\n",
       "       0.02988391, 0.00736928, 0.00814432, 0.0054593 , 0.01342771,\n",
       "       0.01099368, 0.01342771, 0.0044697 , 0.01214989, 0.01099368,\n",
       "       0.01099368, 0.00736928, 0.00900086, 0.006668  , 0.00493978])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/farha/Documents/m1-6-numpy/data/iris.csv')\n",
    "array = df['sepallength'].to_numpy()\n",
    "\n",
    "array2 = np.exp(array - np.max(array))\n",
    "array2 / array2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00221959, 0.00181724, 0.00148783, 0.00134625, 0.00200836,\n",
       "       0.00299613, 0.00134625, 0.00200836, 0.00110221, 0.00181724,\n",
       "       0.00299613, 0.00164431, 0.00164431, 0.00099732, 0.0044697 ,\n",
       "       0.00404435, 0.00299613, 0.00221959, 0.00404435, 0.00221959,\n",
       "       0.00299613, 0.00221959, 0.00134625, 0.00221959, 0.00164431,\n",
       "       0.00200836, 0.00200836, 0.00245302, 0.00245302, 0.00148783,\n",
       "       0.00164431, 0.00299613, 0.00245302, 0.00331123, 0.00181724,\n",
       "       0.00200836, 0.00331123, 0.00181724, 0.00110221, 0.00221959,\n",
       "       0.00200836, 0.00121813, 0.00110221, 0.00200836, 0.00221959,\n",
       "       0.00164431, 0.00221959, 0.00134625, 0.00271101, 0.00200836,\n",
       "       0.01483991, 0.00814432, 0.01342771, 0.00331123, 0.00900086,\n",
       "       0.00404435, 0.00736928, 0.00181724, 0.00994749, 0.00245302,\n",
       "       0.00200836, 0.00493978, 0.0054593 , 0.00603346, 0.00365948,\n",
       "       0.01099368, 0.00365948, 0.0044697 , 0.006668  , 0.00365948,\n",
       "       0.00493978, 0.00603346, 0.00736928, 0.00603346, 0.00814432,\n",
       "       0.00994749, 0.01214989, 0.01099368, 0.0054593 , 0.00404435,\n",
       "       0.00331123, 0.00331123, 0.0044697 , 0.0054593 , 0.00299613,\n",
       "       0.0054593 , 0.01099368, 0.00736928, 0.00365948, 0.00331123,\n",
       "       0.00331123, 0.00603346, 0.0044697 , 0.00200836, 0.00365948,\n",
       "       0.00404435, 0.00404435, 0.006668  , 0.00221959, 0.00404435,\n",
       "       0.00736928, 0.0044697 , 0.01640064, 0.00736928, 0.00900086,\n",
       "       0.02704008, 0.00181724, 0.02003179, 0.01099368, 0.01812551,\n",
       "       0.00900086, 0.00814432, 0.01214989, 0.00404435, 0.0044697 ,\n",
       "       0.00814432, 0.00900086, 0.02988391, 0.02988391, 0.0054593 ,\n",
       "       0.01342771, 0.00365948, 0.02988391, 0.00736928, 0.01099368,\n",
       "       0.01812551, 0.006668  , 0.00603346, 0.00814432, 0.01812551,\n",
       "       0.02213855, 0.0365003 , 0.00814432, 0.00736928, 0.00603346,\n",
       "       0.02988391, 0.00736928, 0.00814432, 0.0054593 , 0.01342771,\n",
       "       0.01099368, 0.01342771, 0.0044697 , 0.01214989, 0.01099368,\n",
       "       0.01099368, 0.00736928, 0.00900086, 0.006668  , 0.00493978])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "softmax(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: unique counts\n",
    "\n",
    "\n",
    "Compute the counts of unique values row-wise.\n",
    "\n",
    "Input:\n",
    "```\n",
    "np.random.seed(100)\n",
    "arr = np.random.randint(1,11,size=(6, 10))\n",
    "arr\n",
    "> array([[ 9,  9,  4,  8,  8,  1,  5,  3,  6,  3],\n",
    ">        [ 3,  3,  2,  1,  9,  5,  1, 10,  7,  3],\n",
    ">        [ 5,  2,  6,  4,  5,  5,  4,  8,  2,  2],\n",
    ">        [ 8,  8,  1,  3, 10, 10,  4,  3,  6,  9],\n",
    ">        [ 2,  1,  8,  7,  3,  1,  9,  3,  6,  2],\n",
    ">        [ 9,  2,  6,  5,  3,  9,  4,  6,  1, 10]])\n",
    "```\n",
    "Desired Output:\n",
    "```\n",
    "> [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],\n",
    ">  [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],\n",
    ">  [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],\n",
    ">  [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],\n",
    ">  [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],\n",
    ">  [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]]\n",
    "```\n",
    "Output contains 10 columns representing numbers from 1 to 10. The values are the counts of the numbers in the respective rows.\n",
    "For example, Cell(0,2) has the value 2, which means, the number 3 occurs exactly 2 times in the 1st row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1, 3, 4, 5, 6, 8, 9]), array([1, 2, 1, 1, 1, 2, 2], dtype=int64)),\n",
       " (array([ 1,  2,  3,  5,  7,  9, 10]),\n",
       "  array([2, 1, 3, 1, 1, 1, 1], dtype=int64)),\n",
       " (array([2, 4, 5, 6, 8]), array([3, 2, 3, 1, 1], dtype=int64)),\n",
       " (array([ 1,  3,  4,  6,  8,  9, 10]),\n",
       "  array([1, 2, 1, 1, 2, 1, 2], dtype=int64)),\n",
       " (array([1, 2, 3, 6, 7, 8, 9]), array([2, 2, 2, 1, 1, 1, 1], dtype=int64)),\n",
       " (array([ 1,  2,  3,  4,  5,  6,  9, 10]),\n",
       "  array([1, 1, 1, 1, 1, 2, 2, 1], dtype=int64))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "arr = np.random.randint(1,11,size=(6, 10))\n",
    "arr\n",
    "\n",
    "def unique_counts(arr):\n",
    "    counts_array = [np.unique(row, return_counts=True) for row in arr]\n",
    "    return counts_array\n",
    "\n",
    "unique_counts(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: One-Hot encodings\n",
    "\n",
    "Compute the one-hot encodings (AKA dummy binary variables) for each unique value in the array.\n",
    "\n",
    "Input:\n",
    "```\n",
    "np.random.seed(101) \n",
    "arr = np.random.randint(1,4, size=6)\n",
    "arr\n",
    "#> array([2, 3, 2, 2, 2, 1])\n",
    "```\n",
    "Output:\n",
    "```\n",
    "#> array([[ 0.,  1.,  0.],\n",
    "#>        [ 0.,  0.,  1.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 1.,  0.,  0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 2 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(101) \n",
    "arr = np.random.randint(1,4, size=6)\n",
    "print(arr)\n",
    "\n",
    "def one_hot_encoder(arr):\n",
    "    columns = np.max(arr) + 1\n",
    "    one_hot_encoded = np.eye(columns)[arr]\n",
    "    z = np.delete(one_hot_encoded, 0, 1) #delete extra column of zeros\n",
    "    return z\n",
    "\n",
    "one_hot_encoder(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Let `q` be a NumPy array of length `n` with `q.sum() == 1`.\n",
    "\n",
    "Suppose that `q` represents a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function) over a statistical distribution. Recall that a distribution is an array of probabilities of events.\n",
    "\n",
    "We want to generate a discrete random variable $ x $ such that $ \\mathbb P\\{x = i\\} = q_i $.\n",
    "\n",
    "In other words, `x` takes values in `range(len(q))` and `x = i` with probability `q[i]`.\n",
    "\n",
    "The standard (inverse transform) algorithm is as follows:\n",
    "\n",
    "- Divide the unit interval $ [0, 1] $ into $ n $ subintervals $ I_0, I_1, \\ldots, I_{n-1} $ such that the length of $ I_i $ is $ q_i $.  \n",
    "- Draw a uniform random variable $ U $ on $ [0, 1] $ and return the $ i $ such that $ U \\in I_i $.  \n",
    "\n",
    "\n",
    "The probability of drawing $ i $ is the length of $ I_i $, which is equal to $ q_i $.\n",
    "\n",
    "We can implement the algorithm as follows\n",
    "\n",
    "```python\n",
    "from random import uniform\n",
    "\n",
    "def sample(q):\n",
    "    a = 0.0\n",
    "    U = uniform(0, 1)\n",
    "    for i in range(len(q)):\n",
    "        if a < U <= a + q[i]:\n",
    "            return i\n",
    "        a = a + q[i]\n",
    "```\n",
    "\n",
    "If you can’t see how this works, try thinking through the flow for a simple example, such as `q = [0.25, 0.75]`\n",
    "It helps to sketch the intervals on paper.\n",
    "\n",
    "**Your exercise is to speed it up using NumPy, avoiding explicit loops**\n",
    "\n",
    "- Hint: Use `np.searchsorted` and `np.cumsum`  \n",
    "\n",
    "\n",
    "If you can, implement the functionality as a class called `DiscreteRV`, where\n",
    "\n",
    "- the data for an instance of the class is the vector of probabilities `q`  \n",
    "- the class has a `draw()` method, which returns one draw according to the algorithm described above  \n",
    "\n",
    "\n",
    "If you can, write the method so that `draw(k)` returns `k` draws from `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import uniform\n",
    "import numpy as np\n",
    "\n",
    "def sample(q):\n",
    "    x = np.cumsum(q)\n",
    "    return x.searchsorted(uniform(0, 1))\n",
    "\n",
    "sample(np.array([0.25, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample(q):\n",
    "    a = 0.0\n",
    "    U = uniform(0, 1)\n",
    "    for i in range(len(q)):\n",
    "        if a < U <= a + q[i]:\n",
    "            return i\n",
    "        a = a + q[i]\n",
    "\n",
    "sample([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 Peaks\n",
    "\n",
    "Find all the peaks in a 1D numpy array a. Peaks are points surrounded by smaller values on both sides.\n",
    "\n",
    "Input:\n",
    "```\n",
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "```\n",
    "Desired Output:\n",
    "```\n",
    "#> array([2, 5])\n",
    "```\n",
    "where, 2 and 5 are the positions of peak values 7 and 6.\n",
    "\n",
    "### 1. Solve this usign a regular python for loop\n",
    "\n",
    "### 2. Solve this using no loops and only numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING FOR LOOP\n",
    "\n",
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "\n",
    "def peaks(a):\n",
    "    peak_indices = []\n",
    "    \n",
    "    for i in range(1, len(a)-1):\n",
    "        if a[i] > a[i - 1] and a[i] > a[i + 1]:\n",
    "            peak_indices.append(i)\n",
    "            \n",
    "    return peak_indices\n",
    "\n",
    "peaks(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -2  2  0 -2  2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 5], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING NUMPY\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "\n",
    "difference = np.diff(a)\n",
    "x = np.diff(np.sign(difference)) #diff two times to find the local maximums\n",
    "print(x)\n",
    "peak_indices = np.where(x == -2)[0] + 1\n",
    "peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "\n",
    "peaks = a[1:-1][np.diff(np.diff(a)) < 0]\n",
    "peaks"
   ]
  }
 ],
 "metadata": {
  "date": 1597540028.6350708,
  "filename": "numpy.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "next_doc": {
   "link": "matplotlib",
   "title": "Matplotlib"
  },
  "prev_doc": {
   "link": "need_for_speed",
   "title": "Python for Scientific Computing"
  },
  "title": "NumPy"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
