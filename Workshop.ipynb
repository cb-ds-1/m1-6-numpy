{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is the Average Height of US Presidents?\n",
    "\n",
    "Aggregates available in NumPy can be extremely useful for summarizing a set of values.\n",
    "As a simple example, let's consider the heights of all US presidents.\n",
    "\n",
    "This data is available in the file *president_heights.csv*, which is a simple comma-separated list of labels and values.\n",
    "\n",
    "Find the mean height, the standard deviation of height, and the president who is the smallest and tallest.\n",
    "\n",
    "You can use `pandas` to read in the file if you want, then cast the column to a `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179.73809523809524,\n",
       " 6.931843442745892,\n",
       " order                     4\n",
       " name          James Madison\n",
       " height(cm)              163\n",
       " Name: 3, dtype: object,\n",
       " order                      16\n",
       " name          Abraham Lincoln\n",
       " height(cm)                193\n",
       " Name: 15, dtype: object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('data\\president_heights.csv')\n",
    "data2 = np.array(data['height(cm)'])\n",
    "\n",
    "data2.argmin()\n",
    "data2.argmax()\n",
    "std = data2.std()\n",
    "avg = data2.mean()\n",
    "small = data.iloc[3]\n",
    "tall = data.iloc[15]\n",
    "\n",
    "avg, std, small, tall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Recall the polynomial formula\n",
    "\n",
    "$$\n",
    "p(x) = a_0 + a_1 x + a_2 x^2 + \\cdots a_N x^N = \\sum_{n=0}^N a_n x^n \\tag{1}\n",
    "$$\n",
    "\n",
    "In the **math functions workshop**, you wrote a simple function `p(x, coeff)` to evaluate it without thinking about efficiency.\n",
    "\n",
    "Now write a new function that does the same job, but uses NumPy arrays and array operations for its computations, rather than any form of Python loop.\n",
    "\n",
    "(This is already implemented in `np.poly1d`, but use that only to test your function)\n",
    "\n",
    "- Hint: Use `np.cumprod()`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def poly(x, coeff):\n",
    "    # coeff array for shape\n",
    "    a = np.array(coeff)\n",
    "    # replace all ele with x\n",
    "    a[:] = x\n",
    "    # x**0 == 1\n",
    "    a[0] = 1\n",
    "    # x*x, x*x*x, etc\n",
    "    a = np.cumprod(a)\n",
    "    # array multiplication and sum\n",
    "    return np.sum(a * coeff)\n",
    "\n",
    "poly(5, [2, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 Softmax\n",
    "\n",
    "Read in `data/iris.csv` and compute the [softmax]() of the sepal length. The formula for the softmax function $\\sigma(x)$ for a vector $x = \\{x_0, x_1, ..., x_{n-1}\\}$ is\n",
    "    .$$\\sigma(x)_j = \\frac{e^{x_j}}{\\sum_k e^{x_k}}$$\n",
    "\n",
    "\n",
    "Your result should be equal to the output of `scipy.special.softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00221959, 0.00181724, 0.00148783, 0.00134625, 0.00200836]),\n",
       " array([0.00221959, 0.00181724, 0.00148783, 0.00134625, 0.00200836]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import special\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('data\\iris.csv')\n",
    "data2 = np.array(data['sepallength'])\n",
    "\n",
    "def softmax(arr):\n",
    "    arr = np.array(arr)\n",
    "    mx = sum(np.exp(arr))\n",
    "    return np.exp(arr) / mx\n",
    "\n",
    "a = softmax(data2)\n",
    "b = special.softmax(data2)\n",
    "\n",
    "b[0:5], a[0:5]\n",
    "# these results look the same, \n",
    "# but fail under '==' test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: unique counts\n",
    "\n",
    "\n",
    "Compute the counts of unique values row-wise.\n",
    "\n",
    "Input:\n",
    "```\n",
    "np.random.seed(100)\n",
    "arr = np.random.randint(1,11,size=(6, 10))\n",
    "arr\n",
    "> array([[ 9,  9,  4,  8,  8,  1,  5,  3,  6,  3],\n",
    ">        [ 3,  3,  2,  1,  9,  5,  1, 10,  7,  3],\n",
    ">        [ 5,  2,  6,  4,  5,  5,  4,  8,  2,  2],\n",
    ">        [ 8,  8,  1,  3, 10, 10,  4,  3,  6,  9],\n",
    ">        [ 2,  1,  8,  7,  3,  1,  9,  3,  6,  2],\n",
    ">        [ 9,  2,  6,  5,  3,  9,  4,  6,  1, 10]])\n",
    "```\n",
    "Desired Output:\n",
    "```\n",
    "> [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],\n",
    ">  [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],\n",
    ">  [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],\n",
    ">  [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],\n",
    ">  [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],\n",
    ">  [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]]\n",
    "```\n",
    "Output contains 10 columns representing numbers from 1 to 10. The values are the counts of the numbers in the respective rows.\n",
    "For example, Cell(0,2) has the value 2, which means, the number 3 occurs exactly 2 times in the 1st row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2 1 1 1 0 2 2 0]\n",
      " [2 1 3 0 1 0 1 0 1 1]\n",
      " [0 3 0 2 3 1 0 1 0 0]\n",
      " [1 0 2 1 0 1 0 2 1 2]\n",
      " [2 2 2 0 0 1 1 1 1 0]\n",
      " [1 1 1 1 1 2 0 0 2 1]]\n",
      "[[ 9  9  4  8  8  1  5  3  6  3]\n",
      " [ 3  3  2  1  9  5  1 10  7  3]\n",
      " [ 5  2  6  4  5  5  4  8  2  2]\n",
      " [ 8  8  1  3 10 10  4  3  6  9]\n",
      " [ 2  1  8  7  3  1  9  3  6  2]\n",
      " [ 9  2  6  5  3  9  4  6  1 10]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "arr = np.random.randint(1,11,size=(6, 10))\n",
    "out = np.zeros_like(arr)\n",
    "\n",
    "for i in range(len(arr)):\n",
    "    val, counts = np.unique(arr[i], return_counts=True)\n",
    "    out[i, val-1] = counts\n",
    "\n",
    "print(out, arr, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: One-Hot encodings\n",
    "\n",
    "Compute the one-hot encodings (AKA dummy binary variables) for each unique value in the array.\n",
    "\n",
    "Input:\n",
    "```\n",
    "np.random.seed(101) \n",
    "arr = np.random.randint(1,4, size=6)\n",
    "arr\n",
    "#> array([2, 3, 2, 2, 2, 1])\n",
    "```\n",
    "Output:\n",
    "```\n",
    "#> array([[ 0.,  1.,  0.],\n",
    "#>        [ 0.,  0.,  1.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 0.,  1.,  0.],\n",
    "#>        [ 1.,  0.,  0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onehot(inp):\n",
    "    top = np.argmax(inp)\n",
    "    rows = len(inp)\n",
    "    cols = inp[top]\n",
    "    out = np.zeros((rows, cols))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        out[i, inp[i]-1] = 1\n",
    "    \n",
    "    return out\n",
    "    \n",
    "onehot([2, 3, 2, 2, 2, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Let `q` be a NumPy array of length `n` with `q.sum() == 1`.\n",
    "\n",
    "Suppose that `q` represents a [probability mass function](https://en.wikipedia.org/wiki/Probability_mass_function) over a statistical distribution. Recall that a distribution is an array of probabilities of events.\n",
    "\n",
    "We want to generate a discrete random variable $ x $ such that $ \\mathbb P\\{x = i\\} = q_i $.\n",
    "\n",
    "In other words, `x` takes values in `range(len(q))` and `x = i` with probability `q[i]`.\n",
    "\n",
    "The standard (inverse transform) algorithm is as follows:\n",
    "\n",
    "- Divide the unit interval $ [0, 1] $ into $ n $ subintervals $ I_0, I_1, \\ldots, I_{n-1} $ such that the length of $ I_i $ is $ q_i $.  \n",
    "- Draw a uniform random variable $ U $ on $ [0, 1] $ and return the $ i $ such that $ U \\in I_i $.  \n",
    "\n",
    "\n",
    "The probability of drawing $ i $ is the length of $ I_i $, which is equal to $ q_i $.\n",
    "\n",
    "We can implement the algorithm as follows\n",
    "\n",
    "```python\n",
    "from random import uniform\n",
    "\n",
    "def sample(q):\n",
    "    a = 0.0\n",
    "    U = uniform(0, 1)\n",
    "    for i in range(len(q)):\n",
    "        if a < U <= a + q[i]:\n",
    "            return i\n",
    "        a = a + q[i]\n",
    "```\n",
    "\n",
    "If you can’t see how this works, try thinking through the flow for a simple example, such as `q = [0.25, 0.75]`\n",
    "It helps to sketch the intervals on paper.\n",
    "\n",
    "**Your exercise is to speed it up using NumPy, avoiding explicit loops**\n",
    "\n",
    "- Hint: Use `np.searchsorted` and `np.cumsum`  \n",
    "\n",
    "\n",
    "If you can, implement the functionality as a class called `DiscreteRV`, where\n",
    "\n",
    "- the data for an instance of the class is the vector of probabilities `q`  \n",
    "- the class has a `draw()` method, which returns one draw according to the algorithm described above  \n",
    "\n",
    "\n",
    "If you can, write the method so that `draw(k)` returns `k` draws from `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from random import uniform\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DiscreteRV():\n",
    "    def __init__(self, q):\n",
    "        self.q = q\n",
    "        self.space = np.cumsum(q)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'DiscreteRV(' + str(self.q) + ')'\n",
    "        \n",
    "    def draw(self, k):\n",
    "        for i in range(k):\n",
    "            U = uniform(0,1)\n",
    "            r = np.searchsorted(self.space, U)\n",
    "            print(r)\n",
    "        # r is the result of a single draw as an index of self.space\n",
    "        \n",
    "DRV = DiscreteRV([0.1, 0.25, 0.65])\n",
    "DRV.draw(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 Peaks\n",
    "\n",
    "Find all the peaks in a 1D numpy array a. Peaks are points surrounded by smaller values on both sides.\n",
    "\n",
    "Input:\n",
    "```\n",
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "```\n",
    "Desired Output:\n",
    "```\n",
    "#> array([2, 5])\n",
    "```\n",
    "where, 2 and 5 are the positions of peak values 7 and 6.\n",
    "\n",
    "### 1. Solve this usign a regular python for loop\n",
    "\n",
    "### 2. Solve this using no loops and only numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def peak_find(arr):\n",
    "    out = []\n",
    "    n = len(arr)\n",
    "    for i in range(1, n-1):\n",
    "        if arr[i] > arr[i-1] & arr[i] > arr[i+1]:\n",
    "            out.append(i)\n",
    "            \n",
    "    return out\n",
    "\n",
    "peak_find([1, 3, 7, 1, 2, 6, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loopless_peak(inp):\n",
    "    \n",
    "    lshift = np.roll(inp, -1)\n",
    "    rshift = np.roll(inp, 1)\n",
    "    lcheck = np.where(inp - lshift > 0)\n",
    "    rcheck = np.where(inp - rshift > 0)\n",
    "    out = np.intersect1d(lcheck, rcheck)\n",
    "    return out\n",
    "\n",
    "# Note, this design doesn't account for \n",
    "# 'peaks' in the [0] or [-1] positions \n",
    "\n",
    "test = [1,3,2,4,3]\n",
    "loopless_peak(test)"
   ]
  }
 ],
 "metadata": {
  "date": 1597540028.6350708,
  "filename": "numpy.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "next_doc": {
   "link": "matplotlib",
   "title": "Matplotlib"
  },
  "prev_doc": {
   "link": "need_for_speed",
   "title": "Python for Scientific Computing"
  },
  "title": "NumPy"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
